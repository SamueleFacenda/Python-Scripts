{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56df3cd1-d397-4d07-828f-dee5b31e0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import ResNet50, ResNet101\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be9bbe17-372d-4363-92b5-f08953cdf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate ResNet50 model\n",
    "model50 = ResNet50(weights='imagenet')\n",
    "model50.trainable = False\n",
    "\n",
    "# instantiate ResNet101 model\n",
    "model101 = ResNet101(weights='imagenet')\n",
    "model101.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c93638e-7d95-4e78-b49e-162536fbba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = 'bernie.png'\n",
    "LABELS_PATH = 'labels.txt'\n",
    "SIDE = 224\n",
    "ALPHA = 0.5\n",
    "IMAGES_BATCH = 200\n",
    "\n",
    "with open(LABELS_PATH) as f:\n",
    "    labels = f.read()\n",
    "    labels = eval(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "235d69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101_target = 742\n",
    "resnet50_target = 353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "995e8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = image.load_img(IMG_PATH)\n",
    "base_img = image.img_to_array(base_img)\n",
    "assert base_img.shape == (SIDE, SIDE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd9497b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnd_noise_img():\n",
    "    return np.random.uniform(0, 255, (SIDE, SIDE, 3))\n",
    "\n",
    "def mix_images(img1, img2, alpha):\n",
    "    return alpha * img1 + (1 - alpha) * img2\n",
    "\n",
    "def get_batch(img):\n",
    "    return np.array([mix_images(img, get_rnd_noise_img(), ALPHA) for _ in range(IMAGES_BATCH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a021fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_brute_force(nsteps):\n",
    "    count = defaultdict(int)\n",
    "    for i in trange(nsteps):\n",
    "        try:\n",
    "            if i % 10 == 9:\n",
    "                print(count)\n",
    "\n",
    "            batch = get_batch(base_img)\n",
    "            pred50 = model50.predict(batch, batch_size=IMAGES_BATCH, verbose=0)\n",
    "            pred101 = model101.predict(batch, batch_size=IMAGES_BATCH, verbose=0)\n",
    "            pred50 = [x[0][1] for x in decode_predictions(pred50, top=1)]\n",
    "            pred101 = [x[0][1] for x in decode_predictions(pred101, top=1)]\n",
    "            for p in pred50:\n",
    "                count[p] += 1\n",
    "            for p in pred101:\n",
    "                count[p] += 1\n",
    "            if resnet101_target in pred101:\n",
    "                idx = pred101.index(resnet101_target)\n",
    "                print(pred101[idx])\n",
    "                image.save_img('found101.png', batch[idx])\n",
    "            if resnet50_target in pred50:\n",
    "                idx = pred50.index(resnet50_target)\n",
    "                print(pred50[idx])\n",
    "                image.save_img('found50.png', batch[idx])\n",
    "            for idx, (p50, p100) in enumerate(zip(pred50, pred101)):\n",
    "                if p50 == resnet50_target and p100 == resnet101_target:\n",
    "                    print('Found image')\n",
    "                    image.save_img('found.png', batch[idx])\n",
    "                    print(batch[idx])\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cb88d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(model, input_image, input_label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model.predict(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0309ca1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed in object [[[[-616.57306 -696.453   -750.76   ]\n   [-616.57306 -696.453   -750.76   ]\n   [-616.57306 -696.453   -750.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  [[-615.573   -695.453   -749.76   ]\n   [-615.573   -695.453   -749.76   ]\n   [-615.573   -695.453   -749.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  [[-614.573   -694.453   -748.76   ]\n   [-614.573   -694.453   -748.76   ]\n   [-614.573   -694.453   -748.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  ...\n\n  [[-562.573   -647.453   -696.76   ]\n   [-568.573   -653.453   -702.76   ]\n   [-556.573   -641.453   -690.76   ]\n   ...\n   [-703.57306 -790.453   -834.76   ]\n   [-711.57306 -798.453   -842.76   ]\n   [-719.57306 -806.453   -850.76   ]]\n\n  [[-561.573   -646.453   -695.76   ]\n   [-567.573   -652.453   -701.76   ]\n   [-559.573   -644.453   -693.76   ]\n   ...\n   [-711.57306 -798.453   -842.76   ]\n   [-716.57306 -803.453   -847.76   ]\n   [-720.57306 -807.453   -851.76   ]]\n\n  [[-558.573   -643.453   -692.76   ]\n   [-566.573   -651.453   -700.76   ]\n   [-564.573   -649.453   -698.76   ]\n   ...\n   [-707.57306 -794.453   -838.76   ]\n   [-709.57306 -796.453   -840.76   ]\n   [-714.57306 -801.453   -845.76   ]]]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(resnet101_target, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      2\u001b[0m label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(label, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m perturbation \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_adversarial_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel101\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m, in \u001b[0;36mcreate_adversarial_pattern\u001b[0;34m(model, input_image, input_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_adversarial_pattern\u001b[39m(model, input_image, input_label):\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_image)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_object(input_label, prediction)\n",
      "File \u001b[0;32m/nix/store/ji03yz2rnvk7vy234my9vbypl2kjic3z-python3-3.11.9-env/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:871\u001b[0m, in \u001b[0;36mGradientTape.watch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor):\n\u001b[1;32m    863\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that `tensor` is being traced by this tape.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m    ValueError: if it encounters something that is not a tensor.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_extract_tensors_and_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbackprop_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsTrainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_first_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWARN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe dtype of the watched tensor must be \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    875\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloating (e.g. tf.float32), got \u001b[39;49m\u001b[38;5;132;43;01m%r\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/ji03yz2rnvk7vy234my9vbypl2kjic3z-python3-3.11.9-env/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:698\u001b[0m, in \u001b[0;36m_extract_tensors_and_variables\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[38;5;28;01myield from\u001b[39;00m _extract_tensors_and_variables(components)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassed in object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    699\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, not tf.Tensor or tf.Variable or ExtensionType.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Passed in object [[[[-616.57306 -696.453   -750.76   ]\n   [-616.57306 -696.453   -750.76   ]\n   [-616.57306 -696.453   -750.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  [[-615.573   -695.453   -749.76   ]\n   [-615.573   -695.453   -749.76   ]\n   [-615.573   -695.453   -749.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  [[-614.573   -694.453   -748.76   ]\n   [-614.573   -694.453   -748.76   ]\n   [-614.573   -694.453   -748.76   ]\n   ...\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]\n   [-565.573   -649.453   -702.76   ]]\n\n  ...\n\n  [[-562.573   -647.453   -696.76   ]\n   [-568.573   -653.453   -702.76   ]\n   [-556.573   -641.453   -690.76   ]\n   ...\n   [-703.57306 -790.453   -834.76   ]\n   [-711.57306 -798.453   -842.76   ]\n   [-719.57306 -806.453   -850.76   ]]\n\n  [[-561.573   -646.453   -695.76   ]\n   [-567.573   -652.453   -701.76   ]\n   [-559.573   -644.453   -693.76   ]\n   ...\n   [-711.57306 -798.453   -842.76   ]\n   [-716.57306 -803.453   -847.76   ]\n   [-720.57306 -807.453   -851.76   ]]\n\n  [[-558.573   -643.453   -692.76   ]\n   [-566.573   -651.453   -700.76   ]\n   [-564.573   -649.453   -698.76   ]\n   ...\n   [-707.57306 -794.453   -838.76   ]\n   [-709.57306 -796.453   -840.76   ]\n   [-714.57306 -801.453   -845.76   ]]]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType."
     ]
    }
   ],
   "source": [
    "label = tf.one_hot(resnet101_target, 1000)\n",
    "label = tf.reshape(label, (1, 1000))\n",
    "\n",
    "perturbation = create_adversarial_pattern(model101, preprocess_input(base_img)[None, ...], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a6196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
